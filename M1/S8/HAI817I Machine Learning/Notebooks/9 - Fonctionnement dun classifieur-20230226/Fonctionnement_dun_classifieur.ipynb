{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Fonctionnement dun classifieur.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDaVRO5vaHYQ"
      },
      "source": [
        "<H1> Mieux comprendre le fonctionnement d'un classifieur </H1>\n",
        "\n",
        "Comme nous l'avons vu dans les premières classifications, le comportement des classifieurs peut être très différent. Nous présentons à présent les régions de décisions dans lesquelles le classifieur recherche les valeurs pour pouvoir prédire. L'objectif est donc ici de mieux comprendre le fonctionnement d'un classifieur, les raisons d'une bonne ou mauvaise classification et avoir une idée de l'impact des hyperparamètres.    \n",
        "\n",
        "Dans un problème de classification à deux classes, une région de décision ou surface de décision est une hypersurface qui partitionne l'espace vectoriel sous-jacent en deux ensembles : un pour chaque classe. Le classificateur classera tous les points d'un côté de la limite de décision comme appartenant à une classe et tous ceux de l'autre côté comme appartenant à l'autre classe.  \n",
        "\n",
        "Les illustrations sont faites à partir du jeu de données IRIS et nous retenons celui disponible dans scikit learn et qui a été introduit à la fin du notebook Ingénierie des données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_qcUq1MvVId"
      },
      "source": [
        "## **Installation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u8pSxqLukpD"
      },
      "source": [
        "\n",
        "Avant de commencer, il est nécessaire de déjà posséder dans son environnement toutes les librairies utiles. Dans la seconde cellule nous importons toutes les librairies qui seront utiles à ce notebook. Il se peut que, lorsque vous lanciez l'éxecution de cette cellule, une soit absente. Dans ce cas il est nécessaire de l'installer. Pour cela dans la cellule suivante utiliser la commande :  \n",
        "\n",
        "*! pip install nom_librairie*  \n",
        "\n",
        "**Attention :** il est fortement conseillé lorsque l'une des librairies doit être installer de relancer le kernel de votre notebook.\n",
        "\n",
        "**Remarque :** même si toutes les librairies sont importées dès le début, les librairies utiles pour des fonctions présentées au cours de ce notebook sont ré-importées de manière à indiquer d'où elles viennent et ainsi faciliter la réutilisation de la fonction dans un autre projet.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Tjn20mvVIe"
      },
      "source": [
        "# utiliser cette cellule pour installer les librairies manquantes\n",
        "# pour cela il suffit de taper dans cette cellule : !pip install nom_librairie_manquante\n",
        "# d'exécuter la cellule et de relancer la cellule suivante pour voir si tout se passe bien\n",
        "# recommencer tant que toutes les librairies ne sont pas installées ...\n",
        "\n",
        "\n",
        "#!pip install ..\n",
        "\n",
        "# ne pas oublier de relancer le kernel du notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQnrkTo7vVIe"
      },
      "source": [
        "# Importation des différentes librairies utiles pour le notebook\n",
        "\n",
        "#Sickit learn met régulièrement à jour des versions et \n",
        "#indique des futurs warnings. \n",
        "#ces deux lignes permettent de ne pas les afficher.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# librairies générales\n",
        "import pickle # pour charger le modèle\n",
        "import pandas as pd\n",
        "import string\n",
        "from random import randint\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "import time\n",
        "import numpy as np\n",
        "import base64\n",
        "import sys\n",
        "\n",
        "# librairie affichage\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "import matplotlib.gridspec as gridspec\n",
        "import itertools\n",
        "\n",
        "# librairies scikit learn\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVGaiRHpvVIh"
      },
      "source": [
        "Pour pouvoir lire et sauvegarder sur votre répertoire Google Drive, il est nécessaire de fournir une autorisation. Pour cela il suffit d'éxecuter la ligne suivante et de saisir le code donné par Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49lXKKjvVIi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiFyG2zivVIj"
      },
      "source": [
        "Corriger éventuellement la ligne ci-dessous pour mettre le chemin vers un répertoire spécifique dans votre répertoire google drive : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfc18opqvVIj"
      },
      "source": [
        "my_local_drive='/content/gdrive/My Drive/Colab Notebooks/ML_FDS'\n",
        "# Ajout du path pour les librairies, fonctions et données\n",
        "sys.path.append(my_local_drive)\n",
        "# Se positionner sur le répertoire associé\n",
        "%cd $my_local_drive\n",
        "\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51n069KEaHYX"
      },
      "source": [
        "Pour pouvoir afficher l'espace de décision, le plus simple est de se mettre dans un espace en 2 dimensions. Par la suite nous ne considérerons que les 2 attributs *sepal length* et *sepal width* dans notre jeu de données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-aSHlcQaHYX"
      },
      "source": [
        "\n",
        "print ('Lecture du fichier iris\\n')\n",
        "iris = datasets.load_iris()\n",
        "#sélection des deux attributs sepals\n",
        "X = iris.data[:, :2]  \n",
        "y = iris.target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZE5EVLQaHYX"
      },
      "source": [
        "Affichage des valeurs des attributs afin de voir comment elles se répartissent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DghQoLukaHYY"
      },
      "source": [
        "\n",
        "#Passage par un dataframe par soucis de simplification\n",
        "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
        "iris_df['species'] = iris['target']\n",
        "\n",
        "colours = ['red', 'orange', 'blue']\n",
        "species = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "for i in range(0, 3):    \n",
        "    species_df = iris_df[iris_df['species'] == i]    \n",
        "    plt.scatter(        \n",
        "        species_df['sepal length (cm)'],        \n",
        "        species_df['sepal width (cm)'],\n",
        "        cmap=plt.cm.coolwarm, \n",
        "        color=colours[i],        \n",
        "        alpha=0.5,        \n",
        "        label=species[i]   \n",
        "    )\n",
        "\n",
        "plt.xlabel('Sepal length (cm)')\n",
        "plt.ylabel('Sepal width (cm)')\n",
        "plt.title('Iris dataset: petal length vs petal width')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCGee_H-aHYY"
      },
      "source": [
        "Comme nous pouvons le constater Setosa est très séparée des autres classes et doit pouvoir facilement être séparé. Il est évident que la séparation entre Versicolor et Virginica va être plus difficile pour un classifieur.  \n",
        "\n",
        "\n",
        "Création d'un jeu de données d'apprentissage et de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc5pjQJSaHYZ"
      },
      "source": [
        "validation_size=0.3 #30% du jeu de données pour le test\n",
        "\n",
        "testsize= 1-validation_size\n",
        "seed=30\n",
        "X_train,X_test,y_train,y_test=train_test_split(X, y, \n",
        "                                               train_size=validation_size, \n",
        "                                               random_state=seed,\n",
        "                                               test_size=testsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8AneMX8aHYZ"
      },
      "source": [
        "Test de 4 classifieurs différents pour voir comment ils se comportent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLLDIPtbaHYZ"
      },
      "source": [
        "lr=LogisticRegression(random_state=1,\n",
        "                          solver='newton-cg',\n",
        "                          multi_class='multinomial')\n",
        "\n",
        "gnb = GaussianNB()\n",
        "deci= DecisionTreeClassifier(random_state=1)\n",
        "svm = SVC(gamma='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGHzMVrOaHYa"
      },
      "source": [
        "Pour afficher les régions de décisions, nous utilisons la librairie mlxtend (cf notebook règles d'association) qui offre de nombreuses facilités pour afficher la zone.  \n",
        "\n",
        "Le principe consiste à parcourir la liste des classifieurs, de faire le fit, de faire la prédiction et d'afficher la zone de décision. Cette zone correspond aux différentes valeurs dans lesquelles pour une classe, le clasifieur va chercher ses valeurs. La zone est définie par rapport à l'ensemble des données. La fonction plot_decision_regions va récupérer les valeurs min et max de tous les attributs et ensuite en fonction de la classe va plutôt étendre ou modifier la zone.   \n",
        "\n",
        "Ci-dessous une fonction qui appelle plot_decision_regions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMx5IUKEaHYa"
      },
      "source": [
        "def call_decision_regions_iris (labels,list_clf,X_train,y_train,X_test,y_test):\n",
        "    # pour afficher les points du jeu de test plus clair\n",
        "    scatter_kwargs = {'s': 120, 'edgecolor': None, 'alpha': 0.7}\n",
        "    contourf_kwargs = {'alpha': 0.2}\n",
        "    scatter_highlight_kwargs = {'s': 120, 'label': 'Jeu de test', 'alpha': 0.7}\n",
        "    \n",
        "    #pour afficher les 4 valeurs sur 2 colonnes et 2 lignes\n",
        "    gs = gridspec.GridSpec(2, 2)\n",
        "\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    \n",
        "    for clf, label, grd in zip(list_clf,\n",
        "                         labels,\n",
        "                         itertools.product([0, 1], repeat=2)):\n",
        "        #fit du modele\n",
        "        clf.fit(X_train, y_train)\n",
        "    \n",
        "        #prediction sur le jeu de test\n",
        "        result=clf.predict(X_test)\n",
        "        acc=accuracy_score(result, y_test)\n",
        "    \n",
        "        #affichage de la zone de décision\n",
        "        ax = plt.subplot(gs[grd[0], grd[1]])\n",
        "        fig=plot_decision_regions(X, y, clf=clf, legend=2,\n",
        "                      X_highlight=X_test,\n",
        "                      scatter_kwargs=scatter_kwargs,\n",
        "                      contourf_kwargs=contourf_kwargs,\n",
        "                      scatter_highlight_kwargs=scatter_highlight_kwargs)\n",
        "\n",
        "\n",
        "\n",
        "        L = plt.legend()\n",
        "        L.get_texts()[0].set_text('Setosa')\n",
        "        L.get_texts()[1].set_text('Versicolor')\n",
        "        L.get_texts()[2].set_text('Virginica')\n",
        "        accu='%0.3f'%acc\n",
        "        plt.xlabel('sepal length [cm]')\n",
        "        plt.ylabel('petal length [cm]')\n",
        "        label=label+ \" (\"+accu+')'\n",
        "        plt.title(label, size=11)\n",
        "    plt.show()\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTCXdYdaHYb"
      },
      "source": [
        "Vous pouvez constater qu'en fonction de la stratégie de l'algorithme les zones sont très différentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aIUoTaHaHYb"
      },
      "source": [
        "labels = ['Logistic Regression',\n",
        "          'Naive Bayes',\n",
        "          'Decision Tree',\n",
        "          'SVM']\n",
        "list_clf=[lr,gnb,deci,svm]\n",
        "\n",
        "call_decision_regions_iris (labels,list_clf,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdGJUtoZaHYb"
      },
      "source": [
        "Nous allons, à présent, tester le même classifieur mais des hyperparamètres différents. L'objectif ici est de montrer l'importance de ces choix dans un classifieur.   \n",
        "\n",
        "Dans l'exemple nous prenons le classifieur SVM. Tout d'abord avec un kernel (noyau) linéaire. Dans ce cas, la séparation entre les différentes classes se fait à l'aide de droites. Le second est LinearSVC. Il est un peu similaire au précédent mais l'implémentation est différente notamment sur la prise en compte du choix des pénalités et des fonctions de pertes. Il se comporte mieux que le précédent dans le cas de plus gros volumes de données. Le troisième est SVM avec un noyeau de type 'rbf'. Il s'agit d'une Radial Basis Function qui prend comme paramètre gamma (le paramètre qui permet de spécifier la région de décision) et C (la pénalité pour les données mal classées. Si C est petit le classifieur est ok pour les points mal classés). Enfin le dernier considére un polynome de degré trois. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XjrAGVWaHYc"
      },
      "source": [
        "C = 1.0  # valeur de pénalité\n",
        "svc = SVC(kernel='linear', C=C)\n",
        "# LinearSVC (linear kernel)\n",
        "lin_svc = LinearSVC(max_iter=2000,C=C)\n",
        "# SVC avec noyau RBF\n",
        "rbf_svc = SVC(kernel='rbf', gamma=0.7, C=C)\n",
        "# SVC avec noyeau polynomial de degre 3\n",
        "poly_svc = SVC(kernel='poly', degree=3, C=C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "E6PJfwFjaHYc"
      },
      "source": [
        "labels = ['SVC avec un kernel linéaire',\n",
        "          'LinearSVC',\n",
        "          'SVC avec un kernel RBF',\n",
        "          'SVC avec un kernel polynomial de degré 3']\n",
        "list_clf=[svc,lin_svc,rbf_svc,poly_svc]\n",
        "call_decision_regions_iris (labels,list_clf,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJLC-ZlMaHYd"
      },
      "source": [
        "Dans l'exemple suivant nous étudions différentes valeurs de gamma pour voir l'impact de SVM avec un kernel rbf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFdSJNylaHYd"
      },
      "source": [
        "C = 1.0  \n",
        "\n",
        "# SVC avec des valeurs différentes de gamma\n",
        "rbf_svc1 = SVC(kernel='rbf', gamma=1, C=C)\n",
        "rbf_svc2 = SVC(kernel='rbf', gamma=10, C=C)\n",
        "rbf_svc3 = SVC(kernel='rbf', gamma=50, C=C)\n",
        "rbf_svc4 = SVC(kernel='rbf', gamma=100, C=C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOAS9nUvaHYd"
      },
      "source": [
        "labels = ['SVC RBF gamma=1',\n",
        "          'SVC RBF gamma=10',\n",
        "          'SVC RBF gamma=50',\n",
        "          'SVC RBF gamma=100']\n",
        "list_clf=[rbf_svc1,rbf_svc2,rbf_svc3,rbf_svc4]\n",
        "call_decision_regions_iris (labels,list_clf,X_train,y_train,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}