{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Utiliser un modèle appris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoH63vJjvVId"
      },
      "source": [
        "<H1> Utilisation d'un modèle </H1>\n",
        "\n",
        "\n",
        "Lors de l'étape précédente, nous avons créé un modèle. L'objectif ici est d'utiliser ce modèle sur de nouvelles données. Dans un premier temps, nous allons tricher un peu en reprenant le même jeu de données. Dans un second temps nous utilisons un autre jeu de données et évaluons la qualité du modèle appris. \n",
        "\n",
        "**Attention** le modèle sauvegardé (*SentimentModel.pkl*) est déjà considéré comme appris et normalement doit être disponible sur votre répertoire - voir notebook classification de données textuelles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_qcUq1MvVId"
      },
      "source": [
        "## **Installation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u8pSxqLukpD"
      },
      "source": [
        "\n",
        "Avant de commencer, il est nécessaire de déjà posséder dans son environnement toutes les librairies utiles. Dans la seconde cellule nous importons toutes les librairies qui seront utiles à ce notebook. Il se peut que, lorsque vous lanciez l'éxecution de cette cellule, une soit absente. Dans ce cas il est nécessaire de l'installer. Pour cela dans la cellule suivante utiliser la commande :  \n",
        "\n",
        "*! pip install nom_librairie*  \n",
        "\n",
        "**Attention :** il est fortement conseillé lorsque l'une des librairies doit être installer de relancer le kernel de votre notebook.\n",
        "\n",
        "**Remarque :** même si toutes les librairies sont importées dès le début, les librairies utiles pour des fonctions présentées au cours de ce notebook sont ré-importées de manière à indiquer d'où elles viennent et ainsi faciliter la réutilisation de la fonction dans un autre projet.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Tjn20mvVIe"
      },
      "source": [
        "# utiliser cette cellule pour installer les librairies manquantes\n",
        "# pour cela il suffit de taper dans cette cellule : !pip install nom_librairie_manquante\n",
        "# d'exécuter la cellule et de relancer la cellule suivante pour voir si tout se passe bien\n",
        "# recommencer tant que toutes les librairies ne sont pas installées ...\n",
        "\n",
        "\n",
        "#!pip install ..\n",
        "\n",
        "# ne pas oublier de relancer le kernel du notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQnrkTo7vVIe"
      },
      "source": [
        "# Importation des différentes librairies utiles pour le notebook\n",
        "\n",
        "#Sickit learn met régulièrement à jour des versions et \n",
        "#indique des futurs warnings. \n",
        "#ces deux lignes permettent de ne pas les afficher.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# librairies générales\n",
        "import pickle # pour charger le modèle\n",
        "import pandas as pd\n",
        "import string\n",
        "from random import randint\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "import time\n",
        "import numpy as np\n",
        "import base64\n",
        "import sys\n",
        "\n",
        "# librairie affichage\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# librairies scikit learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# librairies associées à NLTK\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVGaiRHpvVIh"
      },
      "source": [
        "Pour pouvoir lire et sauvegarder sur votre répertoire Google Drive, il est nécessaire de fournir une autorisation. Pour cela il suffit d'éxecuter la ligne suivante et de saisir le code donné par Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49lXKKjvVIi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiFyG2zivVIj"
      },
      "source": [
        "Corriger éventuellement la ligne ci-dessous pour mettre le chemin vers un répertoire spécifique dans votre répertoire google drive : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfc18opqvVIj"
      },
      "source": [
        "my_local_drive='/content/gdrive/My Drive/Colab Notebooks/ML_FDS'\n",
        "# Ajout du path pour les librairies, fonctions et données\n",
        "sys.path.append(my_local_drive)\n",
        "# Se positionner sur le répertoire associé\n",
        "%cd $my_local_drive\n",
        "\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqGOXYAsoIO"
      },
      "source": [
        "# fonctions utilities (affichage, confusion, etc.)\n",
        "from MyNLPUtilities import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v-zw12KPic0"
      },
      "source": [
        "## **Chargement et utilisation d'un modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNdbfkMVvVIk"
      },
      "source": [
        "   \n",
        "\n",
        "Dans le notebook de classification de textes, nous avons crée un modèle et nous l'avons sauvegardé en utilisant pickle. L'objectif, à présent, est de montrer comment ce modèle appris peut être utilisé sur de nouvelles données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kw1Bvl9vVIk"
      },
      "source": [
        "Dans un premier temps il faut charger le modèle. Nous considérons que le modèle est sauvegardé sur le répertoire indiqué par la variable path préalablement initialisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipTz0Nq_vVIk"
      },
      "source": [
        "import pickle\n",
        "\n",
        "print (\"Chargement du modèle \\n\")\n",
        "\n",
        "filename = 'SentimentModel.pkl'\n",
        "\n",
        "\n",
        "# le chargement se fait via la fonction load\n",
        "clf_loaded = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "# affichage du modèle sauvegardé\n",
        "print (clf_loaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaDTPQltvVIl"
      },
      "source": [
        "<font color=red>Exercice :</font> le code précédent ne fonctionne pas et annonce une erreur : \"Can't get attribute 'TextNormalizer' on <module '__main__'>\", pourquoi ? que proposez vous ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZtBPVQwvVIl"
      },
      "source": [
        "<font color=blue>Solution :</font>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKgZ3saO3qHG"
      },
      "source": [
        "# actuellement le modèle utilise une classe (*TextNormalizer*) ainsi qu'une fonction\n",
        "# (*MyCleanText*) que vous avez créé pour faire les pré-traitements. \n",
        "# Pickle, lorsqu'il sauvegarde le modèle ne sauvegarde que l'appel à la fonction \n",
        "# sans le corps de cette dernière (C.f. notebook \" Classification de donnees). \n",
        "# En d'autres termes, il ne connait pas le contenu de la classe ni de la fonction \n",
        "# et ne peut donc pas les exécuter.  \n",
        "\n",
        "# Pour permettre que le modèle puisse avoir accés à ce contenu, \n",
        "# il est nécessaire de créér un fichier contenant la classe et la fonction. \n",
        "\n",
        "# Attention : TextNormalizer et MyCleanText utilisent également des librairies et \n",
        "# ces dernières doivent etre importeés dans le fichier. \n",
        "\n",
        "# L'importation se fait en précisant le nom de la classe et de la fonction que l'on souhaite recupérer :\n",
        "\n",
        "from CleanText import TextNormalizer, MyCleanText\n",
        "\n",
        "# ou par from CleanText import *\n",
        "\n",
        "\n",
        "# exemple d'utilisation pour montrer que la classe a bien été importée\n",
        "texte = \"This is an example of using the Function MyCleanText before creating a vector created, this text has some problems like 1 c or even numbers like 13 and we have corpora\"\n",
        "\n",
        "print (\" Texte d'origine :\", texte,'  ')\n",
        "print ('Utilisationde MyClean Text avec les parametres par défaut (suppression des stopwords, racinisation, minuscule, etc) :')\n",
        "print (MyCleanText(texte),'  ')\n",
        "\n",
        "print ('Utilisationde MyClean Text avec convertion en minuscule, en prenant les racines, en supprimant les nombres :')\n",
        "print (MyCleanText(texte,lowercase=True,getstemmer=True, removedigit=True),'  ')\n",
        "\n",
        "print ('Utilisationde MyClean Text avec convertion en minuscule et en mettant sous la forme de lemmes :')\n",
        "print (MyCleanText(texte,lowercase=True,getlemmatisation=True),' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx-a9blCvVIm"
      },
      "source": [
        "Nous pouvons, à présent, charger le modèle : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvZr9tgFvVIn"
      },
      "source": [
        "filename = 'SentimentModel.pkl'\n",
        "\n",
        "# le chargement se fait via la fonction load\n",
        "clf_loaded = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "# affichage du modèle sauvegardé\n",
        "print (clf_loaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAWHr29WPpqz"
      },
      "source": [
        "## **Test sur le jeu de données initial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BEBeFPUvVIn"
      },
      "source": [
        "\n",
        "\n",
        "Pour faire un premier test, nous allons tricher un peu ! Nous allons utiliser un échantillon des données issues du jeu de données sur lequel nous avons appris ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMEY5RI6C2iA"
      },
      "source": [
        "!wget https://www.lirmm.fr/~poncelet/Ressources/ReviewsLabelled.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TefccPb6vVIo"
      },
      "source": [
        "df_donnees = pd.read_csv(\"ReviewsLabelled.csv\", names=['sentence','sentiment','source'], \n",
        "                 header=0,sep='\\t', encoding='utf8')\n",
        "\n",
        "print (df_donnees.shape)\n",
        "\n",
        "# sélection d'un échantillon \n",
        "nb_samples=700\n",
        "print (\"Sélection aléatoire de \",nb_samples,\" documents \\n\")\n",
        "\n",
        "samples=[]\n",
        "samples_result=[]\n",
        "sample_new=[]\n",
        "for i in range(0,nb_samples):\n",
        "    val=randint(1,df_donnees.shape[0]-1)\n",
        "    sample_new.append(val)\n",
        "    samples.append(df_donnees.sentence[val])\n",
        "    samples_result.append(df_donnees.sentiment[val])\n",
        "    \n",
        "print (\"Prédiction sur \",nb_samples,\" données tirées au hasard \\n\") \n",
        "\n",
        "y_test=samples_result \n",
        "\n",
        "y_pred = clf_loaded.predict(samples)\n",
        "\n",
        "# autres mesures et matrice de confusion\n",
        "MyshowAllScores(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKEo_W_DvVIp"
      },
      "source": [
        "Comme nous pouvons le constater, le modèle appliqué .... sur les données sur lesquelles nous avons appris ... donne heureusement de très bons résultats. Aussi, pour réellement analyser la qualité de notre modèle nous  allons utiliser un autre jeu de données de sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiJi2iXjPvkg"
      },
      "source": [
        "## **Test sur un autre jeu de données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f5Gk8ayvVIp"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Dans ce test nous utilisons un autre jeu de données issus d'avis sur des films (issu également d'imdb). L'objectif est de voir si le modèle que nous avons appris en considérant des avis sur amazon, sur yelp et sur imbd et assez performant.\n",
        "Le fichier peut être récupéré à l'adresse suivante : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvPSVSAzvVIq"
      },
      "source": [
        "!wget https://www.lirmm.fr/~poncelet/Ressources/movie_data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u4RUHZpvVIr"
      },
      "source": [
        "df_autresdonnees = pd.read_csv(\"movie_data.csv\", names=['review','sentiment'], \n",
        "                 header=0,sep=',', encoding='utf8')\n",
        "print (\"Les cinq premières lignes \\n\")\n",
        "print (df_autresdonnees.head())\n",
        "print (\"\\nUn exemple de review : \\n\",df_autresdonnees.review[0])\n",
        "\n",
        "# selection d'un echantillon\n",
        "nbsamples=800\n",
        "df_sample=df_autresdonnees.sample(n = nbsamples) \n",
        "\n",
        "print (\"\\nPrédiction sur \",nbsamples,\" données tirées au hasard \\n\")       \n",
        "y_test=df_sample.sentiment \n",
        "X=df_sample.review\n",
        "y_pred = clf_loaded.predict(X)\n",
        "\n",
        "# autres mesures et matrice de confusion\n",
        "MyshowAllScores(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRYoYJbbvVIr"
      },
      "source": [
        "Nous constatons que le modèle est nettement moins performant.\n",
        "\n",
        "Dans la suite, nous apprenons un nouveau modèle à partir de ce nouveau jeu de données. Par soucis de simplification (... de nombreuses expérimentations avec gridsearch ont été réalisées ...), et étant donné que l'apprentissage du modèle avec les paramètres et hyperparamètres suivants \n",
        "\n",
        "*pipelinefinal=Pipeline([(\"cleaner\", TextNormalizer(getlemmatisation= 'True',removedigit= 'True', removestopwords= 'True')),  \n",
        "                   (\"tfidf\", TfidfVectorizer(lowercase='True')),  \n",
        "                   ('svm', SVC(C=1, gamma=1,kernel='rbf'))])*  \n",
        "                   \n",
        "est très long, nous fournissons le modèle appris.    \n",
        "\n",
        "Ce modèle a été créé à partir de 90% du jeu de données de manière à conserver 10% (les données ont été triées avant de les répartir) qui pourront être utilisés comme jeu de test (contrairement à la première expérimentation où le test a été effectué sur le jeu de données sur lequel nous avions appris ...)\n",
        "\n",
        "Vous pouvez récupérer le nouveau modèle ainsi que le jeu de données pour effectuer la prédiction ici :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODXZQKi3vVIs"
      },
      "source": [
        "!wget https://www.lirmm.fr/~poncelet/Ressources/NewSentimentModel.pkl\n",
        "!wget https://www.lirmm.fr/~poncelet/Ressources/movie_data_to_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIPKdOXhvVIs"
      },
      "source": [
        "<font color=red>Exercice :</font> charger le nouveau modèle *NewSentimentModel.pkl* et évaluer le sur les données de *movie_data_to_test.csv*. Que pensez vous des performances de ce nouveau modèle ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73iXeTQCt2qR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMmMqDkDvVIs"
      },
      "source": [
        "<font color=blue>Solution :</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8PFsLSD5SW2"
      },
      "source": [
        "# il suffit de charger le modele et de l'appliquer avec predict. \n",
        "# Comme nous pouvons le constater les resultats sont maintenant de 0.90 d'accuracy \n",
        "# contrairement aux 0.77 du premier modele. Même s'il s'agit d'avis exprimes, \n",
        "# nous constatons  que meme si l'on a appris un modele sur un jeu de donnees d'avis ... \n",
        "# cela ne veut pas dire qu'il sera efficace sur d'autres jeux de donnees d'avis... \n",
        "# ici le premier modele contient egalement des avis tres différents (sur des objets, sur des lieux, ...) \n",
        "# et le vocabulaire utilise n'est forcement pas le meme que pour des opinions exprimees uniquement sur des films. \n",
        "\n",
        "# le chargement se fait via la fonction load\n",
        "nouveaumodel = pickle.load(open('NewSentimentModel.pkl', 'rb'))\n",
        "\n",
        "# affichage du modele sauvegarde\n",
        "print (\"le modèle sauvegardé : \",nouveaumodel,' ')\n",
        "\n",
        "# chargement des donnees a tester \n",
        "df_atester=pd.read_csv('movie_data_to_test.csv', names=['review','sentiment'], \n",
        "                 header=0,sep=',', encoding='utf8')\n",
        "print (\"prédictions sur le jeu de données movie_data_to_test qui contient \",df_atester.shape[0],' avis')\n",
        "X_test=df_atester.review\n",
        "y_test=df_atester.sentiment\n",
        "y_pred = nouveaumodel.predict(X_test)\n",
        "\n",
        "# autres mesures et matrice de confusion\n",
        "MyshowAllScores(y_test,y_pred)\n",
        "\n",
        "\n",
        "# le nouveau modele est vraiment plus performant. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5HzBUKAvVIu"
      },
      "source": [
        "<font color=red>Exercice :</font> à partir du premier jeu de données (*ReviewsLabelled.csv*), générer un échantillon et tester le nouveau modèle sur cet échantillon pour voir si le nouveau modèle est performant pour ce jeu de données. Le nom de variable pour le dataframe du premier jeu de données est *df_donnees* et le nom du nouveau modèle est *nouveaumodel*. Comparer les valeurs obtenues par rapport à ceux obtenus dans le notebook précédent. Que pouvez vous dire du nouveau modèle ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7REoPqIJvVIu"
      },
      "source": [
        "<font color=blue>Solution :</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_BRJyY66IOt"
      },
      "source": [
        "# il suffit de prendre un echantillon sur df_donnees et de faire la prediction sur ces donnees \n",
        "# avec nouveaumodel (nouveaumodel.predict (samples)). \n",
        "# En fait le nouveau modele obtient une accuracy d'a peu pres 0.81 ce qui est assez similaire \n",
        "# a celui que nous avions obtenu pour lorsque nous avions appris sur le jeu de donnees precedent. \n",
        "# Ici le fait d'avoir plus de documents pour apprendre permet aussi de pouvoir obtenir un meilleur modele. \n",
        "\n",
        "# selection d'un echantillon \n",
        "nb_samples=700\n",
        "print (\"Selection aleatoire de \",nb_samples,\" documents \")\n",
        "\n",
        "samples=[]\n",
        "samples_result=[]\n",
        "sample_new=[]\n",
        "for i in range(0,nb_samples):\n",
        "    val=randint(1,df_donnees.shape[0]-1)\n",
        "    sample_new.append(val)\n",
        "    samples.append(df_donnees.sentence[val])\n",
        "    samples_result.append(df_donnees.sentiment[val])\n",
        "    \n",
        "print (\"Prediction sur \",nb_samples,\" donnees tirees au hasard \") \n",
        "\n",
        "y_test=samples_result \n",
        "\n",
        "y_pred = nouveaumodel.predict(samples)\n",
        "\n",
        "# autres mesures et matrice de confusion\n",
        "MyshowAllScores(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79TyOdbvVIu"
      },
      "source": [
        "Comme nous pouvons le constater le nouveau modèle s'applique bien sur le jeu de données précédents... il reste cependant encore beaucoup de travail à faire pour avoir un modèle  efficace qui soit capable de déterminer les opinions dans tous les textes et cela est un véritable travail de recherche ... "
      ]
    }
  ]
}